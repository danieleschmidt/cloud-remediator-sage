# Chaos Engineering Configuration for Cloud Remediator Sage
# Advanced resilience testing and failure injection

apiVersion: v1
kind: ConfigMap
metadata:
  name: chaos-engineering-config
  namespace: default
data:
  # ===================================================================
  # CHAOS EXPERIMENTS CONFIGURATION
  # ===================================================================
  
  # Lambda Function Chaos Experiments
  lambda_experiments:
    - name: "lambda_timeout_injection"
      description: "Inject artificial delays to test timeout handling"
      targets:
        - "prowler-ingest"
        - "risk-scoring"
        - "remediation-generator"
      parameters:
        delay_ms: [1000, 5000, 10000, 30000]
        probability: 0.1
        duration: "5m"
      validation:
        - "circuit_breaker_triggers"
        - "retry_mechanisms_active"
        - "error_handling_graceful"
    
    - name: "lambda_memory_pressure"
      description: "Simulate memory exhaustion scenarios"
      targets:
        - "risk-scoring"
      parameters:
        memory_consumption_mb: [400, 450, 500]
        duration: "3m"
      validation:
        - "garbage_collection_metrics"
        - "out_of_memory_handling"
        - "performance_degradation_alerts"
    
    - name: "lambda_cold_start_amplification"
      description: "Force cold starts to test initialization resilience"
      targets: ["*"]
      parameters:
        force_cold_start: true
        concurrent_invocations: [10, 50, 100]
        duration: "10m"
      validation:
        - "initialization_time_metrics"
        - "concurrent_execution_limits"
        - "resource_allocation_efficiency"

  # Neptune Database Chaos Experiments  
  neptune_experiments:
    - name: "connection_pool_exhaustion"
      description: "Exhaust Neptune connection pool"
      parameters:
        max_connections: 100
        connection_hold_time: "30s"
        duration: "5m"
      validation:
        - "connection_pool_monitoring"
        - "query_queue_management"
        - "fallback_mechanism_activation"
    
    - name: "query_latency_injection"
      description: "Inject artificial latency into Gremlin queries"
      parameters:
        latency_ms: [500, 2000, 5000, 10000]
        affected_queries: ["vertex_traversal", "edge_analysis"]
        probability: 0.2
      validation:
        - "query_timeout_handling"
        - "result_caching_effectiveness"
        - "user_experience_metrics"
    
    - name: "partial_graph_corruption"
      description: "Simulate partial data corruption scenarios"
      parameters:
        corruption_percentage: [1, 5, 10]
        affected_data_types: ["vertices", "edges", "properties"]
        duration: "15m"
      validation:
        - "data_integrity_checks"
        - "corruption_detection_algorithms"
        - "recovery_mechanisms"

  # S3 Storage Chaos Experiments
  s3_experiments:
    - name: "intermittent_failures"
      description: "Simulate S3 service intermittent failures"
      parameters:
        failure_rate: [0.05, 0.1, 0.2]
        failure_types: ["503_service_unavailable", "500_internal_error", "timeout"]
        duration: "10m"
      validation:
        - "retry_exponential_backoff"
        - "alternative_storage_fallback"
        - "data_integrity_preservation"
    
    - name: "bandwidth_throttling"
      description: "Throttle S3 bandwidth to test performance"
      parameters:
        bandwidth_limit_mbps: [1, 5, 10]
        affected_operations: ["upload", "download"]
        duration: "8m"
      validation:
        - "upload_timeout_handling"
        - "streaming_performance_metrics"
        - "user_feedback_systems"

  # Network Chaos Experiments
  network_experiments:
    - name: "vpc_endpoint_failures"
      description: "Simulate VPC endpoint connectivity issues"
      parameters:
        failure_duration: ["30s", "2m", "5m"]
        affected_services: ["s3", "neptune", "cloudwatch"]
      validation:
        - "service_degradation_handling"
        - "alternative_connectivity_paths"
        - "monitoring_alert_accuracy"
    
    - name: "dns_resolution_delays"
      description: "Inject DNS resolution delays"
      parameters:
        delay_ms: [1000, 5000, 10000]
        affected_domains: ["*.amazonaws.com"]
        probability: 0.15
      validation:
        - "dns_caching_effectiveness"
        - "connection_reuse_patterns"
        - "service_discovery_resilience"

  # Application-Level Chaos Experiments
  application_experiments:
    - name: "autonomous_backlog_interruption"
      description: "Interrupt autonomous backlog processing"
      parameters:
        interruption_types: ["process_kill", "resource_exhaustion", "exception_injection"]
        timing: ["startup", "mid_execution", "shutdown"]
        duration: "3m"
      validation:
        - "graceful_shutdown_mechanisms"
        - "state_persistence_integrity"
        - "recovery_time_objectives"
    
    - name: "security_scanner_data_corruption"
      description: "Corrupt incoming security scan data"
      parameters:
        corruption_types: ["invalid_json", "missing_fields", "malformed_data"]
        corruption_rate: [0.01, 0.05, 0.1]
        duration: "5m"
      validation:
        - "input_validation_robustness"
        - "error_recovery_mechanisms"
        - "data_quality_monitoring"

  # ===================================================================
  # EXPERIMENT SCHEDULING
  # ===================================================================
  
  scheduling:
    # Regular chaos experiments (non-production)
    development:
      frequency: "daily"
      time_window: "09:00-17:00 UTC"
      max_concurrent_experiments: 2
      auto_rollback_threshold: "error_rate > 5%"
    
    # Production chaos experiments (limited scope)
    production:
      frequency: "weekly"
      time_window: "02:00-04:00 UTC"
      max_concurrent_experiments: 1
      auto_rollback_threshold: "error_rate > 1%"
      approval_required: true
      
    # Game days (comprehensive testing)
    game_days:
      frequency: "monthly"
      duration: "4h"
      scope: "full_system"
      stakeholder_notification: true

  # ===================================================================
  # MONITORING AND OBSERVABILITY
  # ===================================================================
  
  monitoring:
    metrics:
      - name: "experiment_success_rate"
        type: "gauge"
        description: "Percentage of chaos experiments that complete successfully"
        labels: ["experiment_type", "environment", "target_service"]
      
      - name: "recovery_time"
        type: "histogram"
        description: "Time taken for system to recover from chaos injection"
        buckets: [1, 5, 10, 30, 60, 300]
        labels: ["experiment_name", "failure_type"]
      
      - name: "blast_radius"
        type: "counter"
        description: "Number of services affected during chaos experiments"
        labels: ["experiment_type", "severity_level"]
    
    alerts:
      - name: "chaos_experiment_failure"
        condition: "experiment_success_rate < 0.8"
        severity: "warning"
        notification_channels: ["slack", "email"]
      
      - name: "extended_recovery_time"
        condition: "recovery_time > 300s"
        severity: "critical"
        notification_channels: ["pagerduty", "slack"]
      
      - name: "unexpected_blast_radius"
        condition: "blast_radius > expected_impact * 1.5"
        severity: "high"
        notification_channels: ["slack", "email"]

  # ===================================================================
  # SAFETY MECHANISMS
  # ===================================================================
  
  safety:
    circuit_breakers:
      - service: "neptune_database"
        failure_threshold: 5
        timeout: "30s"
        half_open_max_calls: 3
      
      - service: "s3_operations"
        failure_threshold: 10
        timeout: "60s"
        half_open_max_calls: 5
    
    rollback_triggers:
      - condition: "error_rate > 5%"
        action: "immediate_rollback"
        notification: true
      
      - condition: "response_time > p99_baseline * 3"
        action: "gradual_rollback" 
        grace_period: "2m"
      
      - condition: "availability < 99%"
        action: "emergency_stop"
        escalation: "incident_commander"
    
    steady_state_validation:
      pre_experiment_checks:
        - "system_health_green"
        - "no_active_incidents"
        - "resource_utilization < 70%"
        - "error_rate < 1%"
      
      post_experiment_checks:
        - "all_services_responding"
        - "data_integrity_verified"
        - "no_resource_leaks"
        - "performance_within_sla"

  # ===================================================================
  # LEARNING AND IMPROVEMENT
  # ===================================================================
  
  learning:
    experiment_analysis:
      automatic_report_generation: true
      include_metrics_analysis: true
      compare_with_baseline: true
      generate_improvement_recommendations: true
    
    knowledge_sharing:
      post_experiment_reviews: true
      share_findings_with_team: true
      update_runbooks: true
      contribute_to_chaos_engineering_community: true
    
    continuous_improvement:
      track_mttr_improvements: true
      measure_confidence_in_system: true
      identify_new_failure_modes: true
      evolve_experiment_complexity: true

  # ===================================================================
  # INTEGRATION WITH AUTONOMOUS SYSTEM
  # ===================================================================
  
  autonomous_integration:
    backlog_chaos_experiments:
      - name: "wsjf_calculation_stress_test"
        description: "Stress test WSJF prioritization under high load"
        parameters:
          backlog_size: [100, 500, 1000]
          calculation_complexity: "high"
          concurrent_calculations: [5, 10, 20]
      
      - name: "remediation_template_corruption"
        description: "Test resilience against corrupted remediation templates"
        parameters:
          corruption_types: ["syntax_error", "missing_variables", "invalid_logic"]
          affected_templates: ["aws_security_group", "iam_policy"]
    
    security_chaos_experiments:
      - name: "security_finding_flood"
        description: "Overwhelm system with high volume of security findings"
        parameters:
          findings_per_second: [10, 50, 100]
          finding_types: ["critical", "high", "medium"]
          duration: "10m"
      
      - name: "risk_scoring_data_inconsistency"
        description: "Inject inconsistent risk scoring data"
        parameters:
          inconsistency_types: ["conflicting_cvss", "invalid_asset_criticality"]
          affected_percentage: [1, 5, 10]

  # ===================================================================
  # COMPLIANCE AND GOVERNANCE
  # ===================================================================
  
  governance:
    approval_workflow:
      production_experiments: "security_team_approval_required"
      destructive_tests: "architect_approval_required"
      customer_impact_risk: "product_owner_approval_required"
    
    documentation_requirements:
      experiment_hypothesis: "required"
      expected_impact: "required"
      rollback_plan: "required"
      success_criteria: "required"
    
    audit_trail:
      log_all_experiments: true
      track_approvals: true
      record_outcomes: true
      maintain_history: "indefinitely"

---
# Chaos Engineering Automation Script Reference
apiVersion: v1
kind: ConfigMap
metadata:
  name: chaos-automation-scripts
data:
  run_experiment: |
    #!/bin/bash
    # Usage: ./run_experiment.sh <experiment_name> <environment>
    
    EXPERIMENT_NAME="$1"
    ENVIRONMENT="$2"
    
    echo "🔥 Starting chaos experiment: $EXPERIMENT_NAME"
    echo "Environment: $ENVIRONMENT"
    echo "Timestamp: $(date -Iseconds)"
    
    # Pre-flight checks
    if ! ./scripts/chaos/validate_steady_state.sh; then
        echo "❌ System not in steady state. Aborting experiment."
        exit 1
    fi
    
    # Execute experiment
    node scripts/chaos/execute_experiment.js "$EXPERIMENT_NAME" "$ENVIRONMENT"
    
    # Post-experiment validation
    ./scripts/chaos/validate_recovery.sh
    
    # Generate report
    node scripts/chaos/generate_experiment_report.js "$EXPERIMENT_NAME"
    
    echo "✅ Chaos experiment completed"